{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Youtube Predictive Title').master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.conf.set(\"spark.executor.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.18.1.248:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Youtube Predictive Title</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x119b8dd30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USING SPARK TO LOAD THE DATA FROM LOCAL SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqlContext.read.format('csv').options(header='true', inferschema='true').load('/Users/anggapradiktas/Documents/JupyterNotebook/YT/titleYoutube_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = data.select('videoTitle','viewGroup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+----------+\n",
      "|videoTitle                                                        |viewGroup |\n",
      "+------------------------------------------------------------------+----------+\n",
      "|Di Balik Layar Hiduplah Hari Ini - Dialog Dini Hari | Kejar Tayang|0 - 100000|\n",
      "|Interview with SISITIPSI                                          |0 - 100000|\n",
      "+------------------------------------------------------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_select.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|          videoTitle|      viewGroup|\n",
      "+--------------------+---------------+\n",
      "|Di Balik Layar Hi...|     0 - 100000|\n",
      "|Interview with SI...|     0 - 100000|\n",
      "|SISITIPSI - Joni ...|     0 - 100000|\n",
      "|Realitas - Langka...|     0 - 100000|\n",
      "|Target Operasi - ...|100000 - 200000|\n",
      "|NSI - Petaka Pandawa|     0 - 100000|\n",
      "|Primetime News - ...|     0 - 100000|\n",
      "|Primetime News: J...|     0 - 100000|\n",
      "|360 - Pemuda Berg...|     0 - 100000|\n",
      "|Primetime News - ...|     0 - 100000|\n",
      "|Primetime News - ...|     0 - 100000|\n",
      "|1000 Meter - Mena...|     0 - 100000|\n",
      "|Economic Challeng...|     0 - 100000|\n",
      "|Primetime News - ...|     0 - 100000|\n",
      "|Realitas - Gaduh ...|     0 - 100000|\n",
      "|Target Operasi - ...|     0 - 100000|\n",
      "|NSI - Teka - Teki...|     0 - 100000|\n",
      "|Primetime News - ...|     0 - 100000|\n",
      "|I'm Possible - Ba...|     0 - 100000|\n",
      "|Primetime News - ...|     0 - 100000|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_select.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- videoTitle: string (nullable = true)\n",
      " |-- viewGroup: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_select.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|        viewGroup| count|\n",
      "+-----------------+------+\n",
      "|       0 - 100000|345040|\n",
      "|  100000 - 200000| 18476|\n",
      "|  200000 - 300000|  8614|\n",
      "|  300000 - 400000|  5050|\n",
      "|  400000 - 500000|  3508|\n",
      "|  500000 - 600000|  2473|\n",
      "|  600000 - 700000|  1898|\n",
      "|  700000 - 800000|  1443|\n",
      "|  800000 - 900000|  1188|\n",
      "| 900000 - 1000000|   970|\n",
      "|1000000 - 1100000|   758|\n",
      "|1100000 - 1200000|   691|\n",
      "|1200000 - 1300000|   549|\n",
      "|1300000 - 1400000|   512|\n",
      "|1400000 - 1500000|   422|\n",
      "|1500000 - 1600000|   352|\n",
      "|1600000 - 1700000|   337|\n",
      "|1700000 - 1800000|   311|\n",
      "|1800000 - 1900000|   295|\n",
      "|1900000 - 2000000|   246|\n",
      "+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_select.groupby('viewGroup') \\\n",
    "    .count() \\\n",
    "    .orderBy(col('count').desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select_noNA = data_select.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          videoTitle|count|\n",
      "+--------------------+-----+\n",
      "|\"ILC tvOne \"\"KPK ...|    8|\n",
      "|\"Mario Teguh Supe...|    6|\n",
      "|\"KECIL KECIL HEBA...|    4|\n",
      "|\"Dialog: \"\"Peneng...|    4|\n",
      "|\"Coffee Break - \"...|    3|\n",
      "|\"Indonesia Lawyer...|    3|\n",
      "|\"Cover Story One ...|    3|\n",
      "|\"Cover Story One ...|    3|\n",
      "|Asmara Selebriti ...|    1|\n",
      "|Keberhasilan Lest...|    1|\n",
      "|Palang Pintu Beta...|    1|\n",
      "|Commuter Line - A...|    1|\n",
      "|Festival Ramadan ...|    1|\n",
      "|Opi Safarraz Lata...|    1|\n",
      "|Sering Dijuliti,M...|    1|\n",
      "|Lesti Belajar Men...|    1|\n",
      "|Bentuk Perhatian ...|    1|\n",
      "|Cerita Haru Soima...|    1|\n",
      "|Highlight D'Acade...|    1|\n",
      "|Highlight - Konse...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_select_noNA.groupBy(\"videoTitle\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol = 'videoTitle', outputCol = 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anggapradiktas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stopwordList = nltk.corpus.stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, lower, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = data.select((lower(regexp_replace('videoTitle', \"[^a-zA-Z\\\\s]\", \"\")).alias('videoTitle')), 'viewGroup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|          videoTitle|      viewGroup|\n",
      "+--------------------+---------------+\n",
      "|di balik layar hi...|     0 - 100000|\n",
      "|interview with si...|     0 - 100000|\n",
      "|sisitipsi  joni s...|     0 - 100000|\n",
      "|realitas  langkah...|     0 - 100000|\n",
      "|target operasi  c...|100000 - 200000|\n",
      "| nsi  petaka pandawa|     0 - 100000|\n",
      "|primetime news  m...|     0 - 100000|\n",
      "|primetime news je...|     0 - 100000|\n",
      "|  pemuda bergelar...|     0 - 100000|\n",
      "|primetime news  d...|     0 - 100000|\n",
      "|primetime news  m...|     0 - 100000|\n",
      "| meter  menanti p...|     0 - 100000|\n",
      "|economic challeng...|     0 - 100000|\n",
      "|primetime news  m...|     0 - 100000|\n",
      "|realitas  gaduh d...|     0 - 100000|\n",
      "|target operasi  k...|     0 - 100000|\n",
      "|nsi  teka  teki a...|     0 - 100000|\n",
      "|primetime news  m...|     0 - 100000|\n",
      "|im possible  bant...|     0 - 100000|\n",
      "|primetime news  p...|     0 - 100000|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|               words|      viewGroup|\n",
      "+--------------------+---------------+\n",
      "|[di, balik, layar...|     0 - 100000|\n",
      "|[interview, with,...|     0 - 100000|\n",
      "|[sisitipsi, joni,...|     0 - 100000|\n",
      "|[realitas, langka...|     0 - 100000|\n",
      "|[target, operasi,...|100000 - 200000|\n",
      "|[nsi, petaka, pan...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "|[pemuda, bergelar...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "|[meter, menanti, ...|     0 - 100000|\n",
      "|[economic, challe...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "|[realitas, gaduh,...|     0 - 100000|\n",
      "|[target, operasi,...|     0 - 100000|\n",
      "|[nsi, teka, teki,...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "|[im, possible, ba...|     0 - 100000|\n",
      "|[primetime, news,...|     0 - 100000|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_words_token = regexTokenizer.transform(df_clean).select('words', 'viewGroup')\n",
    "df_words_token.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"im\",\"i'm\",\"di\",\"ke\",\"dari\",\"-\",\"kamu\",\"aku\",\"yang\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = 'viewGroup', outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(data_select_noNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pipelineFit.transform(data_select_noNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+--------------------+-----+\n",
      "|          videoTitle|      viewGroup|               words|            filtered|            features|label|\n",
      "+--------------------+---------------+--------------------+--------------------+--------------------+-----+\n",
      "|Di Balik Layar Hi...|     0 - 100000|[di, balik, layar...|[balik, layar, hi...|(10000,[3,7,81,24...|  0.0|\n",
      "|Interview with SI...|     0 - 100000|[interview, with,...|[interview, with,...|(10000,[351,5700]...|  0.0|\n",
      "|SISITIPSI - Joni ...|     0 - 100000|[sisitipsi, -, jo...|[sisitipsi, joni,...|(10000,[3472],[1.0])|  0.0|\n",
      "|Realitas - Langka...|     0 - 100000|[realitas, -, lan...|[realitas, langka...|(10000,[259,3592,...|  0.0|\n",
      "|Target Operasi - ...|100000 - 200000|[target, operasi,...|[target, operasi,...|(10000,[506,537,6...|  1.0|\n",
      "|NSI - Petaka Pandawa|     0 - 100000|[nsi, -, petaka, ...|[nsi, petaka, pan...|(10000,[4540,5864...|  0.0|\n",
      "|Primetime News - ...|     0 - 100000|[primetime, news,...|[primetime, news,...|(10000,[48,825,10...|  0.0|\n",
      "|Primetime News: J...|     0 - 100000|[primetime, news:...|[primetime, news:...|(10000,[145,478,1...|  0.0|\n",
      "|360 - Pemuda Berg...|     0 - 100000|[360, -, pemuda, ...|[360, pemuda, ber...|(10000,[63,178,87...|  0.0|\n",
      "|Primetime News - ...|     0 - 100000|[primetime, news,...|[primetime, news,...|(10000,[48,270,15...|  0.0|\n",
      "|Primetime News - ...|     0 - 100000|[primetime, news,...|[primetime, news,...|(10000,[48,579,15...|  0.0|\n",
      "|1000 Meter - Mena...|     0 - 100000|[1000, meter, -, ...|[1000, meter, men...|(10000,[119,1049,...|  0.0|\n",
      "|Economic Challeng...|     0 - 100000|[economic, challe...|[economic, challe...|(10000,[694,1025,...|  0.0|\n",
      "|Primetime News - ...|     0 - 100000|[primetime, news,...|[primetime, news,...|(10000,[48,355,40...|  0.0|\n",
      "|Realitas - Gaduh ...|     0 - 100000|[realitas, -, gad...|[realitas, gaduh,...|(10000,[190,3644,...|  0.0|\n",
      "|Target Operasi - ...|     0 - 100000|[target, operasi,...|[target, operasi,...|(10000,[648,2444,...|  0.0|\n",
      "|NSI - Teka - Teki...|     0 - 100000|[nsi, -, teka, -,...|[nsi, teka, teki,...|(10000,[4540,6477...|  0.0|\n",
      "|Primetime News - ...|     0 - 100000|[primetime, news,...|[primetime, news,...|(10000,[48,1513,1...|  0.0|\n",
      "|I'm Possible - Ba...|     0 - 100000|[i'm, possible, -...|[possible, bantin...|(10000,[8991,9030...|  0.0|\n",
      "|Primetime News - ...|     0 - 100000|[primetime, news,...|[primetime, news,...|(10000,[48,1157,1...|  0.0|\n",
      "+--------------------+---------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 316738\n",
      "Test Dataset Count: 79289\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.8,0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(maxIter=20, regParam = 0.3, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_b36ba974fed0, numClasses = 172, numFeatures = 10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = predictions.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|                    videoTitle| viewGroup|                   probability|label|prediction|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|Sekolah Rusak Parah, Korban...|0 - 100000|[0.9850106757150424,0.00366...|  0.0|       0.0|\n",
      "|Live report : Arus mudik 20...|0 - 100000|[0.9840827069961158,0.00450...|  0.0|       0.0|\n",
      "|Live Report : sidang warga ...|0 - 100000|[0.9837374344958764,0.00464...|  0.0|       0.0|\n",
      "|Live report : Arus mudik 20...|0 - 100000|[0.9832732272084416,0.00458...|  0.0|       0.0|\n",
      "|Live Report: Kasus DBD meni...|0 - 100000|[0.983259535969943,0.004479...|  0.0|       0.0|\n",
      "|Firza Husein Penuhi Panggil...|0 - 100000|[0.9831519295791378,0.00461...|  0.0|       0.0|\n",
      "|Akibat Korsleting Listrik, ...|0 - 100000|[0.9828623222250696,0.00464...|  0.0|       0.0|\n",
      "|Petugas Bea Cukai Juanda Te...|0 - 100000|[0.9827444237622174,0.00443...|  0.0|       0.0|\n",
      "|KPK Tetapkan 2 Pegawai BUMN...|0 - 100000|[0.981440923568851,0.005662...|  0.0|       0.0|\n",
      "|Empat Korban Keracunan Mira...|0 - 100000|[0.9814362810509999,0.00491...|  0.0|       0.0|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_test.filter(prediction_test['prediction'] == 0) \\\n",
    ".select('videoTitle', 'viewGroup','probability', 'label', 'prediction') \\\n",
    ".orderBy('probability', ascending = False) \\\n",
    ".show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8124697589318511"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = 'prediction')\n",
    "evaluator.evaluate(prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.save('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol = 'filtered', outputCol = 'rawFeatures', numFeatures=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol = 'rawFeatures', outputCol = 'features', minDocFreq = 5, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_idf = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fit_idf = pipeline_idf.fit(data_select_noNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_idf = pipeline_fit_idf.transform(data_select_noNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|          videoTitle| viewGroup|               words|            filtered|         rawFeatures|            features|label|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|Di Balik Layar Hi...|0 - 100000|[di, balik, layar...|[balik, layar, hi...|(10000,[1313,1682...|(10000,[1313,1682...|  0.0|\n",
      "|Interview with SI...|0 - 100000|[interview, with,...|[interview, with,...|(10000,[1274,1637...|(10000,[1274,1637...|  0.0|\n",
      "|SISITIPSI - Joni ...|0 - 100000|[sisitipsi, -, jo...|[sisitipsi, joni,...|(10000,[1274,1731...|(10000,[1274,1731...|  0.0|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_idf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData1, testData1) = dataset_idf.randomSplit([0.8, 0.2], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(trainingData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_idf = lrModel.transform(testData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|                    videoTitle| viewGroup|                   probability|label|prediction|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|KPK Tetapkan Wali kota Mala...|0 - 100000|[0.9835254567376847,0.00438...|  0.0|       0.0|\n",
      "|Live report : Arus mudik 20...|0 - 100000|[0.9824952518861843,0.00476...|  0.0|       0.0|\n",
      "|Dahnil Anzar Diperiksa Peny...|0 - 100000|[0.9823587398104608,0.00489...|  0.0|       0.0|\n",
      "|Warga Resah Aparat Desa Lak...|0 - 100000|[0.9819520451460084,0.00514...|  0.0|       0.0|\n",
      "|Live report : Arus mudik 20...|0 - 100000|[0.9819414494295952,0.00521...|  0.0|       0.0|\n",
      "|MNC Peduli, Lotte Mart dan ...|0 - 100000|[0.9819024485891807,0.00512...|  0.0|       0.0|\n",
      "|Sekolah Rusak Parah, Korban...|0 - 100000|[0.9818045002213764,0.00455...|  0.0|       0.0|\n",
      "|Live Report : sidang warga ...|0 - 100000|[0.9815199339319132,0.00542...|  0.0|       0.0|\n",
      "|KPK Tetapkan 2 Pegawai BUMN...|0 - 100000|[0.981421394413004,0.005519...|  0.0|       0.0|\n",
      "|Gelar Bazar Beras Murah, De...|0 - 100000|[0.9811247710316565,0.00521...|  0.0|       0.0|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_idf.filter(prediction_idf['prediction'] == 0) \\\n",
    ".select('videoTitle', 'viewGroup', 'probability', 'label', 'prediction') \\\n",
    ".orderBy('probability', ascending=False) \\\n",
    ".show(n=10, truncate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117706314174596"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_idf = MulticlassClassificationEvaluator(predictionCol = 'prediction')\n",
    "evaluator_idf.evaluate(prediction_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lrModel.save('model_idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_CV = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_CV_fit = pipeline_CV.fit(data_select_noNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_CV = pipeline_CV_fit.transform(data_select_noNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_CV, test_CV) = dataset_CV.randomSplit([0.8,0.2], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_CV = LogisticRegression(maxIter = 20, regParam = 0.3, elasticNetParam = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder() \\\n",
    ".addGrid(logreg_CV.regParam, [0.1, 0.3, 0.5]) \\\n",
    ".addGrid(logreg_CV.elasticNetParam, [0.0, 0.1, 0.2]) \\\n",
    ".build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator = logreg_CV, estimatorParamMaps = paramGrid, evaluator = evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(training_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "model_1 = LogisticRegressionModel.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "model_2 = LogisticRegressionModel.load('model_idf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
